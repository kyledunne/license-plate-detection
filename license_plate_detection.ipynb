{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "import math\n",
    "import shutil\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary as torch_summary\n",
    "import cv2\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "import wandb\n",
    "from wandb.integration.ultralytics import add_wandb_callback\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    train_images_folder: str\n",
    "    train_labels_folder: str\n",
    "    val_images_folder: str\n",
    "    val_labels_folder: str\n",
    "    train_csv: str\n",
    "    val_csv: str\n",
    "    yolo_config_yaml: str\n",
    "    training_output_folder: str\n",
    "    device: str\n",
    "\n",
    "    # noinspection PyAttributeOutsideInit\n",
    "    def init(self, training):\n",
    "        self.training = training\n",
    "        if self.training:\n",
    "            os.makedirs(self.training_output_folder, exist_ok=True)\n",
    "\n",
    "        self.train_ids = pd.read_csv(self.train_csv)['id'].to_numpy()\n",
    "        self.val_ids = pd.read_csv(self.val_csv)['id'].to_numpy()\n",
    "\n",
    "        self.seed = 8675309\n",
    "        self.batch_size = 32\n",
    "        self.starting_learning_rate = 3e-4\n",
    "        self.max_epochs = 40\n",
    "        self.patience = 4\n",
    "        self.num_workers = 8 if self.device == 'cuda' else 0\n",
    "        self.pin_memory = self.num_workers > 0\n",
    "        self.image_size = 640\n",
    "        self.use_amp = self.device == 'cuda'\n",
    "        self.verbose = False\n",
    "\n",
    "        self.imagenet_mean_cpu_tensor = torch.tensor(imagenet_mean_array)\n",
    "        self.imagenet_std_cpu_tensor = torch.tensor(imagenet_std_array)\n",
    "        self.channelwise_imagenet_mean_cpu_tensor = self.imagenet_mean_cpu_tensor.view(3, 1, 1)\n",
    "        self.channelwise_imagenet_std_cpu_tensor = self.imagenet_std_cpu_tensor.view(3, 1, 1)\n",
    "        self.imagenet_mean_gpu_tensor = gpu_tensor(imagenet_mean_array)\n",
    "        self.imagenet_std_gpu_tensor = gpu_tensor(imagenet_std_array)\n",
    "        self.channelwise_imagenet_mean_gpu_tensor = self.imagenet_mean_gpu_tensor.view(3, 1, 1)\n",
    "        self.channelwise_imagenet_std_gpu_tensor = self.imagenet_std_gpu_tensor.view(3, 1, 1)\n",
    "\n",
    "        self.model_name = 'yolo26s.pt'\n",
    "\n",
    "\n",
    "config: Config = None\n",
    "\"\"\" Set to environment-relevant config before training/inference \"\"\";"
   ],
   "id": "14d963bdf3e33354",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "local_config = Config(\n",
    "    train_images_folder='data/license_plates/images/train/',\n",
    "    train_labels_folder='data/license_plates/labels/train_wrong_format/',\n",
    "    val_images_folder='data/license_plates/images/val/',\n",
    "    val_labels_folder='data/license_plates/labels/val_wrong_format/',\n",
    "    train_csv='data/train.csv',\n",
    "    val_csv='data/val.csv',\n",
    "    yolo_config_yaml='data/license_plates.yaml',\n",
    "    training_output_folder='data_gen/',\n",
    "    device='cpu',\n",
    ")\n",
    "kaggle_config = Config(\n",
    "    train_images_folder='N/A',\n",
    "    train_labels_folder='N/A',\n",
    "    val_images_folder='N/A',\n",
    "    val_labels_folder='N/A',\n",
    "    train_csv='N/A',\n",
    "    val_csv='N/A',\n",
    "    yolo_config_yaml='/kaggle/input/license_plates_dataset/license_plates.yaml',\n",
    "    training_output_folder='/kaggle/working/',\n",
    "    device='cuda',\n",
    ")"
   ],
   "id": "97f8809277272438",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "imagenet_mean_tuple = (0.485, 0.456, 0.406)\n",
    "imagenet_std_tuple = (0.229, 0.224, 0.225)\n",
    "imagenet_mean_array = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "imagenet_std_array = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "def gpu_tensor(numpy_array):\n",
    "    return torch.tensor(numpy_array, device=config.device)\n",
    "\n",
    "def gpu_image_tensor_to_numpy_array(image_tensor):\n",
    "    image = denormalize(image_tensor, config.channelwise_imagenet_mean_gpu_tensor, config.channelwise_imagenet_std_gpu_tensor)\n",
    "    image = torch.clamp(image, 0, 1)\n",
    "    image = image.permute(1, 2, 0).cpu().numpy()\n",
    "    return (image * 255).astype(np.uint8)\n",
    "\n",
    "def normalize(tensor, mean, std):\n",
    "    return (tensor - mean) / std\n",
    "\n",
    "def denormalize(tensor, mean, std):\n",
    "    return tensor * std + mean\n",
    "\n",
    "def print_model_torchinfo(model: nn.Module):\n",
    "    print(torch_summary(model, input_size=(1, 3, config.image_width, config.image_height)))\n",
    "\n",
    "def print_model(model: nn.Module):\n",
    "    for name, module in model.named_modules():\n",
    "        print(name, \"->\", module.__class__.__name__)\n",
    "\n",
    "def create_dataloader(dataset, shuffle):\n",
    "    return DataLoader(dataset, batch_size=config.batch_size, shuffle=shuffle, num_workers=config.num_workers, pin_memory=config.pin_memory, generator=config.generator)\n",
    "\n",
    "def _num_batches(dataloader):\n",
    "    return math.ceil(len(dataloader.dataset) / config.batch_size)"
   ],
   "id": "200ad60b4749b17b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_val_images_with_ground_truth_bounding_boxes(num_images_to_show = 3):\n",
    "    ids = np.random.choice(config.val_ids, num_images_to_show)\n",
    "    for image_id in ids:\n",
    "        image_path = f'{config.val_images_folder}{image_id}.jpg'\n",
    "        image_label = f'{config.val_labels_folder}{image_id}.txt'\n",
    "        image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "        boxes = []\n",
    "        with open(image_label, 'r') as label_file:\n",
    "            for line in label_file:\n",
    "                coords = [float(c) for c in line.strip().split()[-4:]]\n",
    "                boxes.append(coords)\n",
    "        fig = px.imshow(image)\n",
    "        for (x_min, y_min, x_max, y_max) in boxes:\n",
    "            fig.add_shape(type='rect', x0=x_min, y0=y_min, x1=x_max, y1=y_max, line_color='orange')\n",
    "        fig.show()"
   ],
   "id": "98ea5b1ed1bc5ea8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# config = local_config\n",
    "# config.init(training=False)\n",
    "# plot_val_images_with_ground_truth_bounding_boxes()"
   ],
   "id": "3fcec4f3152115e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_yolo():\n",
    "    # Initialize wandb run (logs hyperparams and enables automatic metric logging)\n",
    "    wandb.init(\n",
    "        project=\"license-plate-detection\",\n",
    "        job_type=\"train\",\n",
    "        config={\n",
    "            \"model\": config.model_name,\n",
    "            \"epochs\": config.max_epochs,\n",
    "            \"batch_size\": config.batch_size,\n",
    "            \"image_size\": config.image_size,\n",
    "            \"lr0\": config.starting_learning_rate,\n",
    "            \"patience\": config.patience,\n",
    "            \"seed\": config.seed,\n",
    "            \"amp\": config.use_amp,\n",
    "            \"device\": config.device,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    model = YOLO(config.model_name)\n",
    "\n",
    "    # Register wandb callback — logs metrics per epoch and checkpoints best model as artifact\n",
    "    add_wandb_callback(model, enable_model_checkpointing=True)\n",
    "\n",
    "    # Train — verbose=True enables per-epoch cell output logging\n",
    "    results = model.train(\n",
    "        data=config.yolo_config_yaml,\n",
    "        epochs=config.max_epochs,\n",
    "        imgsz=config.image_size,\n",
    "        batch=config.batch_size,\n",
    "        lr0=config.starting_learning_rate,\n",
    "        patience=config.patience,\n",
    "        seed=config.seed,\n",
    "        amp=config.use_amp,\n",
    "        workers=config.num_workers,\n",
    "        device=config.device,\n",
    "        verbose=True,\n",
    "        plots=True,\n",
    "    )\n",
    "\n",
    "    # Copy best model weights to config.training_output_folder\n",
    "    best_src = Path(results.save_dir) / \"weights\" / \"best.pt\"\n",
    "    os.makedirs(config.training_output_folder, exist_ok=True)\n",
    "    best_dst = Path(config.training_output_folder) / \"best.pt\"\n",
    "    shutil.copy(str(best_src), str(best_dst))\n",
    "    print(f\"Best model saved to: {best_dst}\")\n",
    "\n",
    "    wandb.finish()\n",
    "    return results\n"
   ],
   "id": "e26111490ceb6b70"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# wandb_key = user_secrets.get_secret(\"wandb_key\")\n",
    "# !wandb login $wandb_key"
   ],
   "id": "382ab92d3c2e3fd4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "config = kaggle_config\n",
    "config.init(training=True)\n",
    "train_yolo()"
   ],
   "id": "941c31940a1f6b54"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
